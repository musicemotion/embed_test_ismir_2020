# embed_test_ismir_2020
This is a repository of ISMIR 2020 paper submission. 

Paper Title: USING DEEP AUDIO EMBEDDINGS FOR MUSIC EMOTIONRECOGNITION

The following steps are needed to run thisÂ emotion recognition demo notebook.

1. Prepare music emotion dataset you want to test
2-1. Extract L3 embedding from music clips
https://openl3.readthedocs.io/en/latest/tutorial.html#introduction

(We also share some l3 embedding samples in this repo for quick testing)

2-2 Extract VGGish embedding from music clips
https://github.com/tensorflow/models/tree/master/research/audioset/vggish

3. Run the notebook for emotion classification using 6 emotion classifiers
4. Enjoy!

